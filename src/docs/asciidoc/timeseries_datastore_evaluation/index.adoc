= Evaluating Timeseries Datastore for massive IoT platform
:doctype: book
:icons: font
:toc: left
:toclevels: 3
:numbered:
:sectlinks:
:sectanchors:
:hardbreaks:
:imagesdir: images

=== Objective

Evaluate few market leading Timeseries Datastores to identify a suitable one to store and process telemetry data generated by IoT Devices. The datastores should be able to address the following challenges currently faced in massive IoT platform,

*	High Ingestion Rate 
*	Reasonable Query Throughput
*	Tools to support Data Lifecycle Management 
*	Linear Scalability 
*	High Availability
*	Maintainability 
*	Multi-tenancy

=== Background

Let us aim in considering the primitive IoT platform, which could have 2 sensors per device sending 2 Metrics/hour. Having said this, the expectation on scaling thy said platform to handle massive IoT devices is as below,

[options="header",cols="1,1,1,1,1"]
|===
|Tenants/Platform| No of Devices(Million)	| Metrics/hour	| Metrics/sec	| No of Records/Month
//----------------------
|1	|2	|2	|1200	|~3 Billion
|5	|10	|2	|6000	|~15 Million
|1	|50	|2	|30K	|~75 Billion
|5	|250	|2	|150K	|~120 Billion
|===

It could be inferred from the above table that, in long term, the platform should be able to handle 150K Metrics/Sec which in turn translates to ~120 Billion Metric records over a period of 30 days in a multi-tenant environment.

=== Scope

Considering the above expectations on the platform, the scope of this evaluation is to 

*	Benchmark using industry standard tool
*	Analyze Performance Characteristics 
*	Capture the pros, cons & caveats of each datastore under evaluation
*	List down the findings in terms of Scalability, High availability, Multi-tenancy, etc.

[NOTE]
====
See <<_use_cases>>  section in Benchmarking strategy to get insights on detailed information on benchmarking.
====


=== Datastores Considered

The datastores considered for evaluation here are,

*	Influx DB
*	Timescale DB

The reason for choosing the above 2 databases are based on,

*	Popular timeseries datastores as of 2019
*	Better fit for Massive IoT systems
*	High community & documentation support

=== Benchmarking Strategy

==== Use Cases

The datastores considered here are evaluated based on the following use-cases,

* Ingestion Rate
* Query Throughput
* Concurrent Read & Write 


===== Ingestion Rate

This section provides the details on evaluating both the datastores based on the insertion rate. 

*Prerequisite:*

* 7 days of data to be generated for each use case using TSBS.

[options="header",cols="1,1,1,1,1"]
|===
|Use case 	| No. of Metrics	| No. of Metrics/Sec	| No of Worker Threads	| Load Type
//----------------------
|uc1 |1 |1200 |8 |Write
|uc2 |1 |1200 |16 |Write
|uc3 |10 |1200 |8 |Write
|uc4 |10 |1200 |16 |Write
|uc5 |1 |6000 |8 |Write
|uc6 |1 |6000 |16 |Write
|uc7 |10 |6000 |8 |Write
|uc8 |10 |6000 |16 |Write
|uc9 |1 |30000 |8 |Write
|uc10 |1 |30000 |16 |Write
|uc11 |10 |30000 |8 |Write
|uc12 |10 |30000 |16 |Write
|===

===== Query Throughput

In timeseries datastore terminology, queries are commonly classified as,

*	Simple Rollup
*	Double Rollup
*	Thresholds
*	Complex queries

[NOTE]
====
This evaluation concentrates more on *Simple Rollup* & *Thresholds* such as overall aggregation.
====

*Prerequisite:*

* Queries to perform a read operation on 7 days data to be generated for each use case using TSBS.

[options="header",cols="1,1,1,1,1"]
|===
|Use Case	|Read Type	|Description	|No of Worker Threads	|Load Type
//----------------------
|uc1	|single-groupby-1-1-1	| Aggregrate on one metric for 1 host, every 5 mins for 1 hour	|8	|Read
|uc2	|single-groupby-1-1-12	| Aggregrate on one metric for 1 host, every 5 mins for 12 hours	|8	|Read
|uc3	|single-groupby-5-1-12	| Aggregrate on 5 metrics for 1 host, every 5 mins for 12 hours	|8	|Read
|uc4	|single-groupby-5-8-1	| Aggregrate on 5 metrics for 8 hosts, every 5 mins for 1 hour	|8	|Read
|uc5	|high-cpu-1	|All the readings where one metric is above a threshold for a particular host	|8	|Read
|===

NOTE: The above queries are run for 2 million, 10 million & 50 million devices.


===== Concurrent Read & Write

*TODO*

==== Tools

*	*TSBS* (Time series Benchmark suite) – To benchmark read & write performance of Influx DB & Timescale DB
*	*Ganglia* – To monitor & record performance metrics like CPU, Disk IOPS, Memory, Network IO, etc.

==== Environment

Following are the system requirements to perform the benchmarking,

*InfluxDB:*

image::influx_system.png[title="Influx DB Environment Setup"]

*Hardware Specifications:*

* 3 standard VMs in Azure (Each with 8 vCPU, 28 GB Memory)
* 3 * 1-TB Premium SSD disks

*Software Specifications:*

* VMs installed with Ubuntu 18.04 LTS
* Influx DB V-2.6
* Ganglia data nodes - gmond daemons in all the nodes to collect performance statistics
* NTPD service -  For time synchronization across all nodes 

NOTE: 3 node setup, since this is the de-facto setup for influx db enterprise version


*TimescaleDB:*

image::tsdb_system.png[title="Timescale DB Environment Setup"]

*Hardware Specifications:*

* 1 standard VM in Azure (Each with 24 vCPU, 62 GB Memory)
* 3 * 1-TB Premium SSD disks with RAID 0 Setup

*Software Specifications:*

* VMs installed with Ubuntu 18.04 LTS
* Timesacle DB  V-1.1.1
* PostgreSQL v-10.6
* Ganglia data node - gmond daemon to collect performance statistics 
* Software RAID configured for 3 data disks


*Client:*

* 1 standard VM in azure (8 vCPU, 28 GB memory)
* Ganglia Meta node - gmetad daemon to collect & publish results

NOTE: To have a minimum of 2000 IOPS, premium SSD Disks are chosen as data disks for both the databases 


==== Performance Metrics

The following characteristics would be measured,

*	Insert rate
*	Query throughput  
*	Resource Utilization (CPU, IO, Memory)
*	Error Percentile
*	Read/Write Latency


=== Evaluation
==== Performance Characteristics
===== Insert rate Comparison

image::insert_rate_8_16_threads.png[title="Insert Rate of Influx Vs Timescale DB"]

On inserts, InfluxDB outperforms TimescaleDB, by distributing the load across the nodes. This is due to the fact that each node in influx has a dedicated data disk, whereas the node running TimescaleDB points to the RAID 0 configured disks, which pretty much cuts the parallel IOPS that can happen on RAID disks.

On consistency perspective, TimescaleDB inserts 100K rows/sec even with the 50 million devices with high cardinality data points.

On data storage perspective, InfluxDB uses high compression standards to write the data to the disk. For instance, 10 million devices which sends 17 billions records/week consumes 750G in TimescaleDB, but 60G in case of InfluxDB evenly distributed across the data nodes(20G per node).

When it comes to performance metrics, CPU load & memory consumed are almost same for both the datastores, but incase of network OPS, TimescaleDB chokes on the outgoing requests when compared to the incoming requests, which is probably due to the write to RAID disks.   

Following ganglia report shows the metrics captured for 10 millions devices sending high cardinality data.

image::uc7-node1.png[title="InfluxDB Performance statistics - 10 million devices"]
image::uc7.png[title="TimescaleDB Performance statistics - 10 million devices"]

TIP: Complete ganglia reports during ingestion for both the datastores can be found in the folder *ganglia_reports* in the project root directory.


===== Query Throughput Comparison

image::query_throughput_comparison.png[title="Query Throughput of Influx Vs Timescale DB"]

on queries, TimescaleDB outperforms InfluxDB in all the cases. This is due to the postgresql backed datastore that is used by TimescaleDB.

The queries for multiple scenarios, are ~25X times faster than InfluxDB.

By considering TimescaleDB as performance baseliner, following graph is plotted in a percentile based system, which explains the performance dip that InfluxDB encounters when compared to its counterpart.

image::performance_dip.png[title="Percentile based Performance comparison"]

==== Additional Characteristics

===== Data life cycle management:
====== Influx

* Influx DB supports data lifecycle management through retention policy & continuous queries.
* Expired data can be deleted by configuring a retention policy. One can manage retention policies using queries, such as CREATE RETENTION_POILICY or ALTER RETENTION_POLICY.
* Allows downsampling of data, which helps in keeping the high precision data for limited time & stores the low precision data for longer time.

====== Timescale

* Timescale DB offers data lifecycle management through retention policy.
* Expired data can be deleted at chink level using SQL commands such as SELECT drop_chunks. It could also be automated by scheduling a CRON job or systemd timer which executes the drop_chunks command during the scheduled period.
  
===== Scalability:
====== Influx

* Supports both scale up and scale out. 
* Scaling influx cluster by adding an additional node, allows the system to distribute the data evenly & load balance the input OPS.


====== Timescale
 
 * Timescale supports only scale up, since it claims to provide a good insertion rate & query throughput using a single node.
 * To scale up the cpu & memory performance, the cores & RAM could be scaled up.
 * To scale up the data volume, another data disk could be added in the RAID 0 array.
 
===== High Availability:
====== Influx

* Influx DB offers the high availability through its distributed nature. Single point of failure is excluded by having a quorum of meta nodes & data nodes , whereas the data high avilability is achieved by having a replication factor enabled.

TIP: In enterprise cluster with 3 meta & data nodes with replication factor of 2, cluster can tolerate atmost one node failure to be highly available  

====== Timescale
 
* Timescale DB does not offer a hassle-free setup for high availability & it needs a lot of custom service to be in place to handle one.
* To exclude single point of failure, timescale expects the user to have secondary instance running. On event of failure in the primary instance, the user has to take care of the failover (i.e) To bring the secondary instance through manual intervention or via custom service.
* It offers data high availability through replication using postgreSQL's built-in streaming replication. 

===== Ecosystem:

* InfluxDB officially supports only the in-house tools that are created by them, such as Chronograf, Kapacitor, Telegraf & Grafana, but unofficially supports widely used open-source technologies & tools.
* Timescale DB provides official support for all the widely used open-source technologies & tools.

Following table highlights some of the tools that are officially supported by TimescaleDB, but not InfluxDB, 
[options="header",cols="1,^,^"]
|===
|Tools   |InfluxDB Support   |TimescaleDB Support   
//----------------------
|Tableau   |image:wrong.png[50,50]   |image:tick.png[50,50]
|PowerBI   |image:wrong.png[50,50]   |image:tick.png[50,50]   
|Kafka   |image:wrong.png[50,50]   |image:tick.png[50,50]   
|Spark   |image:wrong.png[50,50]   |image:tick.png[50,50]   
|Flink   |image:wrong.png[50,50]   |image:tick.png[50,50]
|Zabbix   |image:wrong.png[50,50]   |image:tick.png[50,50]
|Hibernate   |image:wrong.png[50,50]   |image:tick.png[50,50]
|Entity Framework   |image:wrong.png[50,50]   |image:tick.png[50,50]   
|===

===== Security:

TimescaleDB provides support for security in wide areas, whereas InfluxDB lacks in some areas, which is clearly depicted in the following table,

[options="header",cols="1,^,^"]
|===
|Security Category   |InfluxDB   |TimescaleDB   
//----------------------
|Authentication & Authorization   |image:tick.png[50,50]   |image:tick.png[50,50]   
|SSL   |image:tick.png[50,50]   |image:tick.png[50,50]   
|Host Based Access Control   |image:wrong.png[50,50]   |image:tick.png[50,50]   
|Data Encryption at rest   |image:wrong.png[50,50]   |image:tick.png[50,50]   
|Kerberos   |image:wrong.png[50,50]   |image:tick.png[50,50]   
|===


===== Documentation & Community Support:
====== Influx

* For documentation - https://docs.influxdata.com
* For community support - https://community.influxdata.com

====== Timescale

* For documentation - https://docs.timescale.com
* Since Timescale is backed up postgreSQL, it covers wide range of forums to support. However, the problems that could pop up in enteriprise versions are supported through timescale community/blog & slack.

===== Query Language:
====== Influx

Influx DB ships with its own CLI(Command line interface) which helps in querying the data using Influx query language. 

====== Timescale

Timescale uses conventional SQL commands, with additional commands for timeseries operations added as postgreSQL extensions.
 
===== Cloud Support:

Following are the official enterprise support towards deployment in cloud platform given by both the datastores,

[options="header",cols="1,^,^"]
|===
|Cloud Patform   |InfluxDB   |TimescaleDB   
//----------------------
|AWS   |image:tick.png[50,50]   |image:tick.png[50,50]   
|Azure   |image:wrong.png[50,50]    |image:wrong.png[50,50]    
|Google Cloud   |image:wrong.png[50,50]    |image:wrong.png[50,50]    
|===

NOTE: Timescale DB provides a beta version for its deployment in azure. 


=== Summary

==== Influx DB
===== Pros & Caveats
Pros are,

*	Varying but Commendable insertion rate with minimum setup even with high cardinal data points.
*	Consistent load-balancing of IOPS & even load distribution of data among the nodes in the cluster.
*	Easy to scale up & scale out.
*	Due to its distributed nature, it becomes trivial to make the system highly available.
*	Use high compression standards to store the data, which makes it occupy less disk space.

Caveats are,

*	Read latency is high & query throughput is less when compared to its counterpart.
*	Lacks support for popular open-source technologies such as spark, flink, powerBI, & popular ORMs, etc.

==== Timescale DB
===== Pros & Caveats
Pros are,

*	Consistent insertion rate with minimum setup even with high cardinal data points.
*	High Query throughput when compared to its counterpart - almost *~25X faster*
*	Easy to use the query language, since backed up by postgreSQL
*	High support for popular open-source technologies such as spark, flink, powerBI, & popular ORMs, etc.

Caveats are,

*	No hassle free guide for high availabilty & needs manual intervention or custom service to take care of failover in case of single point of failure.
*	Only scale up is supported, cannot scale out.
*	No in-house support for data compression, occupies high disk space.

=== Verdict
One can go with Influx DB, if the required system needs high ingestion rate, but can tolerate on query throughput.Also, it offers hassle free guide for scalability & high availability.

On the other hand, Timescale DB, can be considered if the required system accepts moderate ingestion(consistent 100k requests), & high query throughput. Also, it offers wide range of support to open-source technologies & the beat down to other competitiors comes with the way that it is backed up by postgreSQL. 

=== Glossary

_meta-node_
Node in InfluxDB responsible for storing meta information about the nodes in the influx cluster.

_data-node_
Node in InfluxDB responsible for processing & storing the timeseries data.

_cardinality_
Number of metrics per reading interval sent by a device.

=== References

_[1] Influx DB documentation_ https://docs.influxdata.com/enterprise_influxdb/v1.6/

_[2] Timescale DB documentation_ https://docs.timescale.com/v1.2/main

_[3] Timeseries benchmark suit_e https://github.com/timescale/tsbs

_[4] Configure software RAID array for virtual machines_ https://docs.microsoft.com/en-us/azure/virtual-machines/linux/configure-raid#create-the-raid-array

_[5] Guide to setup ganglia for a cluster_ https://www.javacodegeeks.com/2013/04/ganglia-configuration-for-a-small-hadoop-cluster-and-some-troubleshooting.html


